# ğŸ“˜ Adobe Hackathon Round 2 â€“ Persona-Driven Document Intelligence

## ğŸš€ Challenge Overview

In Round 2 of Adobeâ€™s â€œConnecting the Dotsâ€ Hackathon, the goal is to build an intelligent document analyst that **extracts and prioritizes the most relevant sections from a collection of PDFs**, based on a given **persona** and a **job-to-be-done**.

This round builds on top of Round 1 by introducing **semantic understanding**, **section ranking**, and **contextual refinement**.

---

## ğŸ’¡ What This Project Does

Given:
- A set of PDFs (`/input/*.pdf`)
- A persona file (`persona.txt`)
- A task file (`job_to_be_done.txt`)

The system:
1. Extracts blocks of text using PyMuPDF
2. Scores blocks using a combination of:
   - Font size and position (structure-based)
   - Semantic similarity to persona/task (transformer-based)
3. Selects the **most relevant section** from each document
4. Gathers nearby context and refines it
5. Outputs a JSON file with:
   - Extracted Sections (title, page, rank)
   - Refined Subsections (text, page, document)

---

## ğŸ§  Model and Libraries Used

| Component             | Description                                      |
|----------------------|--------------------------------------------------|
| `fitz` (PyMuPDF)      | PDF parsing and layout extraction               |
| `sentence-transformers` | Semantic similarity scoring (MiniLM-L6-v2)     |
| `langdetect` (optional) | For language-aware extensions (if needed)     |
| `re`, `datetime`, `json` | Standard preprocessing and formatting         |

Transformer Model Used: `all-MiniLM-L6-v2` (approx. 90MB) âœ…

---

## ğŸ— Directory Structure

```
.
â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ file1.pdf
â”‚   â”œâ”€â”€ file2.pdf
â”‚   â”œâ”€â”€ persona.txt
â”‚   â”œâ”€â”€ job_to_be_done.txt
â”‚   â””â”€â”€ input.json (auto-generated if missing)
â”œâ”€â”€ output/
â”‚   â””â”€â”€ output.json (final result)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py (this script)
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸ“¦ How to Build and Run (Dockerized)

### ğŸ”¨ Build Docker Image

```bash
docker build --platform linux/amd64 -t adobe-pdf-agent .
```

### â–¶ï¸ Run Container

```bash
docker run --rm   -v $(pwd)/input:/app/input   -v $(pwd)/output:/app/output   --network none   adobe-pdf-agent
```

â± **Processing Time:** < 10 seconds for 3â€“5 PDFs

---

## ğŸ§¾ Output Format (output/output.json)

```json
{
  "metadata": {
    "input_documents": ["file1.pdf", "file2.pdf"],
    "persona": "Research Analyst",
    "job_to_be_done": "Analyze R&D investment trends",
    "processing_timestamp": "2025-07-27T15:44:32"
  },
  "extracted_sections": [
    {
      "document": "file1.pdf",
      "section_title": "R&D Investment Overview",
      "importance_rank": 1,
      "page_number": 3
    }
  ],
  "subsection_analysis": [
    {
      "document": "file1.pdf",
      "refined_text": "R&D spending has increased by 23%...",
      "page_number": 3
    }
  ]
}
```

---

## ğŸ§ª Example Scenario

**Persona:** PhD Scholar in Environmental Science  
**Task:** Summarize key findings related to climate change in 3 UN reports.

â†’ The model ranks and extracts top headings like _"Climate Impact Summary"_ and refines paragraphs following the heading for context. Final JSON is ready for visualization or embedding in a reading experience.

---

## ğŸ“Œ Constraints Followed

| Constraint              | âœ… Status           |
|-------------------------|--------------------|
| CPU-only (AMD64)        | âœ… Fully compatible |
| Max model size < 1GB    | âœ… Model = ~90MB    |
| No Internet Calls       | âœ… Offline mode     |
| Execution < 60s         | âœ… Runs < 10s       |

---

## ğŸ“ Notes

- The entire logic is implemented in a single `main.py` script for simplicity.
- Works on any domain of documents: research, education, finance, etc.
- You can manually edit `persona.txt` and `job_to_be_done.txt` in the `input/` folder to test custom cases.

---

## ğŸ“ License

MIT License. Built as part of Adobe India Hackathon 2025 (Round 2).
